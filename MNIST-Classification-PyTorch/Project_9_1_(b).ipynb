{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9XK2bWiSD2S0",
        "UpWg5wtsEuN4",
        "LCd3ODfWFTrf",
        "0pUvMbAyF0kO",
        "6SUxshahGIBX",
        "OSe-ByHKGWNT",
        "f0M6d1qcGrip",
        "FOQsl20QG5NN",
        "IcG3jdl_HWGb",
        "OV2f5ycxHdoA",
        "UIGo90njHqBa",
        "CNP6KnWkH-Om"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***1 : Defining Neural Network Class***"
      ],
      "metadata": {
        "id": "gfTVkgLt3ExA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jKpRbTlS3KJl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2 : Flattening the Image***"
      ],
      "metadata": {
        "id": "OU_xeJOE3g-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "sample_img, _ = next(iter(train_loader))\n",
        "flattened_img = flatten(sample_img)\n",
        "print(flattened_img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TVC6OBC3nDy",
        "outputId": "7ed9cd19-d3f7-47fc-b081-d649832f6a51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3 : Adding Hidden Layer***"
      ],
      "metadata": {
        "id": "y8yYJn613fRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-dOeXImQ35Mr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***4 : Adding Output Layer***"
      ],
      "metadata": {
        "id": "dxHt0Sds38oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cU10V6JK4Fdx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***5 : Initializing weights***"
      ],
      "metadata": {
        "id": "GSBEhe0l4KkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "model = SimpleNN()\n",
        "initialize_weights(model)"
      ],
      "metadata": {
        "id": "MFxTlc5Z4RcA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***6 : Using CrossEntropyLoss***"
      ],
      "metadata": {
        "id": "85yXfvXF4YvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "bKaV-XKL4VSf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***7 : Configuring Adam Optimizer***"
      ],
      "metadata": {
        "id": "w55iGP4z4nPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "rOFd0svd4vMp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***8 : Initial Loss Before Training***"
      ],
      "metadata": {
        "id": "dSE2Mg-e4yEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "outputs = model(images)\n",
        "initial_loss = criterion(outputs, labels)\n",
        "print(\"Initial Loss:\", initial_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8sepk3A5LmZ",
        "outputId": "0a27d634-1e21-4ef6-83f3-9113222e771e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Loss: 2.4456543922424316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***9 : Training LOOP***"
      ],
      "metadata": {
        "id": "cIyMlnCu5SPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GqAkqiv5M7Y",
        "outputId": "7c6b8ac5-a257-4cfb-8ff2-2b093229780a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0142\n",
            "Epoch [2/5], Loss: 0.0089\n",
            "Epoch [3/5], Loss: 0.0582\n",
            "Epoch [4/5], Loss: 0.0123\n",
            "Epoch [5/5], Loss: 0.0364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***10 : Evaluating Model Performance***"
      ],
      "metadata": {
        "id": "eQ3OiizS56ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvXcAPiH5_p5",
        "outputId": "cf7bd868-6f5d-49ec-e0e0-c1b32f4f8739"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_preds.extend(predicted.numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro')\n",
        "recall = recall_score(all_labels, all_preds, average='macro')\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2sXu91V6cFZ",
        "outputId": "bcf1de5d-0d82-48a3-ab56-47d80f0c61a8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9774\n",
            "Precision: 0.9775\n",
            "Recall: 0.9772\n",
            "F1-Score: 0.9773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***11 : Adding a Hidden Layer***"
      ],
      "metadata": {
        "id": "R1NjpBZn6nLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2Z_3oG9P6sH8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***12 : Comparing Training Loss and Metric Changes***"
      ],
      "metadata": {
        "id": "gl1F5Onr6vZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepNN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_preds.extend(predicted.numpy())\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro')\n",
        "recall = recall_score(all_labels, all_preds, average='macro')\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czS_c2dj65FI",
        "outputId": "a9c82b47-ae78-49e1-ae4c-42da2f578d7d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Average Loss: 0.2976\n",
            "Epoch [2/5], Average Loss: 0.1123\n",
            "Epoch [3/5], Average Loss: 0.0741\n",
            "Epoch [4/5], Average Loss: 0.0550\n",
            "Epoch [5/5], Average Loss: 0.0401\n",
            "Accuracy: 0.9783\n",
            "Precision: 0.9784\n",
            "Recall: 0.9781\n",
            "F1-Score: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ§© Step: Discussion â€” Trade-offs Between Computation and Accuracy\n",
        "\n",
        "Adding extra hidden layers or increasing neuron counts often improves a modelâ€™s ability to learn complex patterns, but it comes with costs:\n",
        "\n",
        "#### 1. **Computation Time**\n",
        "\n",
        "* More layers and parameters mean more multiplications during training.\n",
        "* Each epoch takes longer to complete, especially on CPUs or smaller GPUs.\n",
        "\n",
        "#### 2. **Memory Usage**\n",
        "\n",
        "* Larger models consume more GPU or RAM memory for weights, gradients, and activations.\n",
        "* This can cause slower data loading and even out-of-memory errors in limited environments.\n",
        "\n",
        "#### 3. **Accuracy and Generalization**\n",
        "\n",
        "* While deeper or wider networks may achieve higher training accuracy, they risk overfitting â€” performing worse on unseen data.\n",
        "* Smaller models might generalize better if the dataset is simple (like MNIST).\n",
        "\n",
        "#### 4. **Optimal Balance**\n",
        "\n",
        "* The best architecture finds balance â€” minimal complexity for maximum performance.\n",
        "* For MNIST, 1â€“2 hidden layers with 128â€“256 neurons typically reach >97% accuracy without unnecessary computation."
      ],
      "metadata": {
        "id": "CaqF2_zS7N7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***13 : Saving Model State***"
      ],
      "metadata": {
        "id": "42KPfd_-7uEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mnist_model_state_dict.pth\")\n",
        "print(\"Model state dictionary saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FRLKTQ27zoX",
        "outputId": "951a3504-736d-458b-a6ab-78a11e4f9866"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model state dictionary saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"mnist_model_state_dict.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6m9ZXoqX8Ayh",
        "outputId": "09caa6e7-2d2b-4655-bf49-a5270cf8ce9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90df0133-413c-49f8-8f55-1e40264c100a\", \"mnist_model_state_dict.pth\", 875529)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}